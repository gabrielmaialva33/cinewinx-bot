import re
import unicodedata

from pyrogram import filters, Client
from pyrogram.types import (
    Message,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
    CallbackQuery,
)

from CineWinx import app
from CineWinx.utils import LexicaClient
from config import PREFIXES, BANNED_USERS
from strings import get_command

LLM_COMMAND = get_command("LLM_COMMAND")

prompt_db: dict = {}

client = LexicaClient()

main_prompt = (
    "VocÃª Ã© a AI do CineWinx. Ao responder, por favor, chame o usuÃ¡rio pelo nome. {0}\n\n"
    "A seguir estÃ¡ o prompt que um usuÃ¡rio enviou para vocÃª:\n\n{1}"
)


@app.on_message(filters.command(LLM_COMMAND, PREFIXES) & ~BANNED_USERS)
async def llm(_client: Client, message: Message):
    prompt = (
        message.text.split(None, 1)[1].strip()
        if len(message.text.split()) > 1
        else (message.reply_to_message.text if message.reply_to_message else None)
    )
    reply_to_id = (
        message.reply_to_message.id if message.reply_to_message else message.id
    )

    user_name = message.from_user.first_name
    user_name = normalize_username(user_name)
    if user_name == "":
        user_name = "User"

    prompt_db[message.from_user.id] = {
        "prompt": prompt,
        "reply_to_id": reply_to_id,
        "user_name": user_name,
        "model_id": None,
        "model_name": None,
    }

    models = client.get_chats_model()

    page = 0
    markup = chat_markup(message.from_user.id, models, page)

    await message.reply_text(
        f"ğŸ¦™ ğ—¦ğ—²ğ—¹ğ—²ğ—°ğ—¶ğ—¼ğ—»ğ—² ğ˜‚ğ—º ğ—ºğ—¼ğ—±ğ—²ğ—¹ğ—¼ ğ—Ÿğ—Ÿğ—  ğŸ‘‡",
        reply_markup=markup,
    )


def chat_markup(
    user_id: int, models: list | dict, page: int = 0
) -> InlineKeyboardMarkup:
    # number of models per page
    models_per_page = 4
    start_index = page * models_per_page
    end_index = start_index + models_per_page

    # select models for the current page
    current_models = models[start_index:end_index]

    # create buttons for models
    buttons = []
    for model in current_models:
        buttons.append(
            InlineKeyboardButton(
                text=model["name"],
                callback_data=f"llm_{user_id}_{model['id']}_{model['name']}",
            )
        )

    # organize buttons in 2x2 grid
    keyboard = [buttons[i : i + 2] for i in range(0, len(buttons), 2)]

    # add navigation buttons
    navigation_buttons = []
    if start_index > 0:
        navigation_buttons.append(
            InlineKeyboardButton(text="â¬…ï¸ ğ—”ğ—»ğ˜ğ—²ğ—¿ğ—¶ğ—¼ğ—¿", callback_data=f"llm_prev_{page}")
        )
    if end_index < len(models):
        navigation_buttons.append(
            InlineKeyboardButton(text="â¡ï¸ ğ—£ğ—¿ğ—¼Ìğ˜…ğ—¶ğ—ºğ—¼", callback_data=f"llm_next_{page}")
        )

    if navigation_buttons:
        keyboard.append(navigation_buttons)

    return InlineKeyboardMarkup(keyboard)


@app.on_callback_query(filters.regex(pattern=r"^llm_(prev|next)_\d+"))
async def paginate_models(_, callback_query: CallbackQuery):
    models = client.get_chats_model()
    data = callback_query.data.split("_")
    page = int(data[2])

    if data[1] == "prev":
        page -= 1
    elif data[1] == "next":
        page += 1

    markup = chat_markup(callback_query.from_user.id, models, page)

    await callback_query.edit_message_reply_markup(markup)


@app.on_callback_query(filters.regex(pattern=r"^llm_\d+_\d+_\w+") & ~BANNED_USERS)
async def select_model(_, callback_query: CallbackQuery):
    chat_id = callback_query.message.chat.id

    user_id = int(callback_query.data.split("_")[1])
    model_id = int(callback_query.data.split("_")[2])
    model_name = callback_query.data.split("_")[3]

    # check if the user is the same as the one who initiated the command
    if callback_query.from_user.id != user_id:
        return await callback_query.answer("âŒ ğ—¡Ã£ğ—¼ ğ—®ğ˜‚ğ˜ğ—¼ğ—¿ğ—¶ğ˜‡ğ—®ğ—±ğ—¼.", show_alert=True)

    prompt_db[user_id]["model_id"] = model_id
    prompt_db[user_id]["model_name"] = model_name

    prompt = main_prompt.format(
        prompt_db[user_id]["user_name"], prompt_db[user_id]["prompt"]
    )
    params = {
        "prompt": prompt,
        "model_id": prompt_db[user_id]["model_id"],
    }

    response = client.fetch(
        url=f"{client.url}/models",
        method="POST",
        params=params,
        json={},
        headers={"content-type": "application/json"},
    )

    if response["code"] != 2:
        return await callback_query.edit_message_text(
            f"ğŸ¦™ ğ— ğ—¼ğ—±ğ—²ğ—¹ğ—¼: {prompt_db[user_id]['model_name']}\n"
            f"âŒ ğ—”ğ—¹ğ—´ğ—¼ ğ—±ğ—²ğ˜‚ ğ—²ğ—¿ğ—¿ğ—¼, ğ˜ğ—²ğ—»ğ˜ğ—² ğ—»ğ—¼ğ˜ƒğ—®ğ—ºğ—²ğ—»ğ˜ğ—² ğ—ºğ—®ğ—¶ğ˜€ ğ˜ğ—®ğ—¿ğ—±ğ—²."
        )

    await callback_query.message.delete()
    await callback_query.message.reply_to_message.reply_text(
        f"ğŸ“ <u>ğ—£ğ—¿ğ—¼ğ—ºğ—½ğ˜</u>: {prompt_db[user_id]['prompt']}"
        f"\nğŸ¦™ <u>ğ— ğ—¼ğ—±ğ—²ğ—¹ğ—¼</u>: {prompt_db[user_id]['model_name']}"
        f"\nğŸ“¬ <u>ğ—¥ğ—²ğ˜€ğ—½ğ—¼ğ˜€ğ˜ğ—®</u>: \n\n"
        f"<i>{response['content']}</i>",
        reply_to_message_id=prompt_db[user_id]["reply_to_id"],
    )


def normalize_username(username: str) -> str:
    normalized = unicodedata.normalize("NFKC", username)
    normalized = re.sub(r"\W+", "", normalized)
    return normalized


__MODULE__ = "ğŸ¦™ ğ—Ÿğ—Ÿğ— "
__HELP__ = """
ğŸ› ï¸ ğ— ğ—¼Ìğ—±ğ˜‚ğ—¹ğ—¼ ğ—±ğ—² ğ—Ÿğ—¶ğ—»ğ—´ğ˜‚ğ—®ğ—´ğ—²ğ—º ğ—±ğ—² ğ—šğ—¿ğ—®ğ—»ğ—±ğ—² ğ—˜ğ˜€ğ—°ğ—®ğ—¹ğ—®

<b>ğŸ“ ğ——ğ—²ğ˜€ğ—°ğ—¿ğ—¶ğ—°Ì§ğ—®Ìƒğ—¼:</b>

- ğ—˜ğ˜€ğ˜ğ—² ğ—ºğ—¼Ìğ—±ğ˜‚ğ—¹ğ—¼ ğ—½ğ—²ğ—¿ğ—ºğ—¶ğ˜ğ—² ğ—¾ğ˜‚ğ—² ğ˜ƒğ—¼ğ—°ğ—²Ì‚ ğ˜‚ğ˜€ğ—² ğ—ºğ—¼ğ—±ğ—²ğ—¹ğ—¼ğ˜€ ğ—±ğ—² ğ—¹ğ—¶ğ—»ğ—´ğ˜‚ğ—®ğ—´ğ—²ğ—º ğ—±ğ—² ğ—´ğ—¿ğ—®ğ—»ğ—±ğ—² ğ—²ğ˜€ğ—°ğ—®ğ—¹ğ—® ğ—½ğ—®ğ—¿ğ—® ğ—´ğ—²ğ—¿ğ—®ğ—¿ ğ˜ğ—²ğ˜…ğ˜ğ—¼ ğ—°ğ—¼ğ—º ğ—¯ğ—®ğ˜€ğ—² ğ—²ğ—º ğ˜‚ğ—º ğ—½ğ—¿ğ—¼ğ—ºğ—½ğ˜.

<b>ğŸ”– ğ—–ğ—¼ğ—ºğ—®ğ—»ğ—±ğ—¼ğ˜€:</b>

â€¢ <code>/llm</code> [ğ˜ğ—²ğ˜…ğ˜ğ—¼]: ğ—šğ—²ğ—¿ğ—² ğ˜ğ—²ğ˜…ğ˜ğ—¼ ğ—°ğ—¼ğ—º ğ—¯ğ—®ğ˜€ğ—² ğ—»ğ—¼ ğ—½ğ—¿ğ—¼ğ—ºğ—½ğ˜ ğ—³ğ—¼ğ—¿ğ—»ğ—²ğ—°ğ—¶ğ—±ğ—¼.

â€¢ <code>/llmgen</code> [ğ˜ğ—²ğ˜…ğ˜ğ—¼]: ğ—šğ—²ğ—¿ğ—² ğ˜ğ—²ğ˜…ğ˜ğ—¼ ğ—°ğ—¼ğ—º ğ—¯ğ—®ğ˜€ğ—² ğ—»ğ—¼ ğ—½ğ—¿ğ—¼ğ—ºğ—½ğ˜ ğ—³ğ—¼ğ—¿ğ—»ğ—²ğ—°ğ—¶ğ—±ğ—¼.

â€¢ <code>/llmgenerate</code> [ğ˜ğ—²ğ˜…ğ˜ğ—¼]: ğ—šğ—²ğ—¿ğ—² ğ˜ğ—²ğ˜…ğ˜ğ—¼ ğ—°ğ—¼ğ—º ğ—¯ğ—®ğ˜€ğ—² ğ—»ğ—¼ ğ—½ğ—¿ğ—¼ğ—ºğ—½ğ˜ ğ—³ğ—¼ğ—¿ğ—»ğ—²ğ—°ğ—¶ğ—±ğ—¼.

â€¢ <code>/llma</code> [ğ˜ğ—²ğ˜…ğ˜ğ—¼]: ğ—šğ—²ğ—¿ğ—² ğ˜ğ—²ğ˜…ğ˜ğ—¼ ğ—°ğ—¼ğ—º ğ—¯ğ—®ğ˜€ğ—² ğ—»ğ—¼ ğ—½ğ—¿ğ—¼ğ—ºğ—½ğ˜ ğ—³ğ—¼ğ—¿ğ—»ğ—²ğ—°ğ—¶ğ—±ğ—¼.

<b>ğŸ’¡ ğ—˜ğ˜…ğ—²ğ—ºğ—½ğ—¹ğ—¼ğ˜€:</b>

â€¢ <code>/llm</code> O que Ã© a vida?
â€¢ <code>/llmgen</code> O que Ã© a vida?
â€¢ <code>/llma</code> Como fazer um bolo?
"""
